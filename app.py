import streamlit as st
import google.generativeai as genai
import yaml
import os

def load_api_key():
    # First try to get API key from environment variable
    api_key = os.getenv('GEMINI_API_KEY')
    if api_key:
        return api_key
        
    # Fallback to config file if environment variable is not set
    try:
        with open('_config.yml', 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
            return config.get('gemini_api', {}).get('key')
    except Exception as e:
        st.error(f'Failed to load API key: {e}')
        return None

def initialize_gemini():
    api_key = load_api_key()
    if api_key:
        genai.configure(api_key=api_key)
        return genai.GenerativeModel('gemini-pro')
    return None

def get_chatbot_response(model, prompt, chat_history):
    base_prompt = """ë‹¹ì‹ ì€ Microsoft Azure í•™ìŠµ ê²½ë¡œ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ë°°ê²½ê³¼ ëª©í‘œë¥¼ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•œ ë§ì¶¤í˜• í•™ìŠµ ê³„íšì„ ì œì‹œí•´ì£¼ì„¸ìš”:
- ì¶”ì²œ í•™ìŠµ ê²½ë¡œ
- í•„ìš”í•œ ì„ ìˆ˜ ì§€ì‹
- ì˜ˆìƒ í•™ìŠµ ê¸°ê°„
- ì£¼ìš” í•™ìŠµ ë‚´ìš©
- ì¶”ì²œ ìê²©ì¦
- ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì œì•ˆ

ë‹µë³€ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    full_prompt = f"{base_prompt}\n\nì´ì „ ëŒ€í™” ë‚´ìš©:\n{chat_history}\n\ní˜„ì¬ ì§ˆë¬¸: {prompt}"
    
    try:
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def main():
    st.title("Azure í•™ìŠµ ê²½ë¡œ ìƒë‹´ ì±—ë´‡ ğŸ’¬")
    
    # Initialize session state for chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Initialize Gemini model
    model = initialize_gemini()
    if not model:
        st.error("API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Get chat history as string
        chat_history = "\n".join([f"{'ì‚¬ìš©ì' if msg['role'] == 'user' else 'ì±—ë´‡'}: {msg['content']}" 
                                for msg in st.session_state.messages[:-1]])

        # Get bot response
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = get_chatbot_response(model, prompt, chat_history)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()